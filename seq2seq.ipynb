{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import numpy as np\n",
    "from text_processing import tokenize_text, untokenize, pad_text, Toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_id = 0\n",
    "\n",
    "device = torch.device('cuda:{}'.format(gpu_id)) \\\n",
    "    if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        assert hidden_size % 2 == 0\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.hidden_init_tensor = torch.zeros(2, 1, int(self.hidden_size/2), requires_grad=True)\n",
    "        nn.init.normal_(self.hidden_init_tensor, mean=0, std=0.05)\n",
    "        self.hidden_init = torch.nn.Parameter(self.hidden_init_tensor, requires_grad=True)\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_drop = nn.Dropout(0.2)\n",
    "        self.gru = nn.GRU(hidden_size, int(hidden_size/2), batch_first=True, bidirectional=True)\n",
    "        self.gru_out_drop = nn.Dropout(0.2)\n",
    "        self.gru_hid_drop = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, input, hidden, lengths):\n",
    "        emb = self.emb_drop(self.embedding(input))\n",
    "        pp = torch.nn.utils.rnn.pack_padded_sequence(emb, lengths, batch_first=True)\n",
    "        out, hidden = self.gru(pp, hidden)\n",
    "        out = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)[0]\n",
    "        out = self.gru_out_drop(out)\n",
    "        hidden = self.gru_hid_drop(hidden)\n",
    "        return out, hidden\n",
    "    \n",
    "    def initHidden(self, bs):\n",
    "        return self.hidden_init.expand(2, bs, int(self.hidden_size/2)).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderAttn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_drop = nn.Dropout(0.2)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.gru_drop = nn.Dropout(0.2)\n",
    "        self.mlp = nn.Linear(hidden_size*2, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.att_mlp = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.attn_softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outs):\n",
    "        emb = self.embedding(input)\n",
    "        out, hidden = self.gru(self.emb_drop(emb), hidden)\n",
    "        \n",
    "        out_proj = self.att_mlp(out)\n",
    "        enc_out_perm = encoder_outs.permute(0, 2, 1)\n",
    "        e_exp = torch.bmm(out_proj, enc_out_perm)\n",
    "        attn = self.attn_softmax(e_exp)\n",
    "        \n",
    "        ctx = torch.bmm(attn, encoder_outs)\n",
    "        \n",
    "        full_ctx = torch.cat([self.gru_drop(out), ctx], dim=2)\n",
    "        \n",
    "        out = self.mlp(full_ctx)\n",
    "        out = self.logsoftmax(out)\n",
    "        return out, hidden, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(enc_vocab_size, dec_vocab_size, \n",
    "                hid_size=512, loaded_state = None):\n",
    "    \n",
    "    enc = Encoder(enc_vocab_size, hid_size)\n",
    "    dec = DecoderAttn(dec_vocab_size, hid_size, dec_vocab_size)\n",
    "    \n",
    "    if loaded_state is not None:\n",
    "        enc.load_state_dict(loaded_state['enc'])\n",
    "        dec.load_state_dict(loaded_state['dec'])\n",
    "        \n",
    "    enc = enc.to(device)\n",
    "    dec = dec.to(device)\n",
    "    \n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_test():\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        loaded_state = torch.load(model_path + seq_to_seq_test_model_fname,\n",
    "                                  map_location=device)\n",
    "    else:\n",
    "        loaded_state = torch.load(model_path + seq_to_seq_test_model_fname,\n",
    "                                  map_location='cpu')\n",
    "\n",
    "    enc_idx_to_word = loaded_state['enc_idx_to_word']\n",
    "    enc_word_to_idx = loaded_state['enc_word_to_idx']\n",
    "    enc_vocab_size = len(enc_idx_to_word)\n",
    "\n",
    "    dec_idx_to_word = loaded_state['dec_idx_to_word']\n",
    "    dec_word_to_idx = loaded_state['dec_word_to_idx']\n",
    "    dec_vocab_size = len(dec_idx_to_word)\n",
    "    \n",
    "    enc, dec = build_model(enc_vocab_size, \n",
    "                           dec_vocab_size, \n",
    "                           loaded_state = loaded_state)\n",
    "    \n",
    "    return {'enc': enc, 'dec': dec,\n",
    "            'enc_idx_to_word': enc_idx_to_word,\n",
    "            'enc_word_to_idx': enc_word_to_idx,\n",
    "            'enc_vocab_size': enc_vocab_size,\n",
    "            'dec_idx_to_word': dec_idx_to_word,\n",
    "            'dec_word_to_idx': dec_word_to_idx,\n",
    "            'dec_vocab_size': dec_vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_packpadded(s, e, enc_padded_text):\n",
    "\n",
    "    text = enc_padded_text[s:e]\n",
    "    lengths = np.count_nonzero(text, axis=1)\n",
    "    order = np.argsort(-lengths)\n",
    "    new_text = text[order]\n",
    "    new_enc = torch.tensor(new_text)\n",
    "    new_enc = new_enc.to(device)\n",
    "    \n",
    "    leng = torch.tensor(lengths[order])\n",
    "    leng.to(device)\n",
    "    return order, new_enc, leng\n",
    "\n",
    "def generate(enc, dec, enc_padded_text, L=20):\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    with torch.no_grad():\n",
    "        # run the encoder\n",
    "        order, enc_pp, enc_lengths = make_packpadded(0, \n",
    "                                                     enc_padded_text.shape[0], \n",
    "                                                     enc_padded_text)\n",
    "        hid = enc.initHidden(enc_padded_text.shape[0])\n",
    "        out_enc, hid_enc = enc(enc_pp, hid, enc_lengths)\n",
    "        \n",
    "        hid_enc = torch.cat([hid_enc[0,:, :], hid_enc[1,:,:]], dim=1).unsqueeze(0)\n",
    "\n",
    "        # run the decoder step by step\n",
    "        dec_tensor = torch.ones((enc_padded_text.shape[0]), \n",
    "                                L + 1, \n",
    "                                dtype=torch.long) * Toks.SOS\n",
    "        dec_tensor = dec_tensor.to(device)\n",
    "        last_enc = hid_enc\n",
    "        for i in range(L):\n",
    "            out_dec, hid_dec, attn = dec.forward(dec_tensor[:,i].unsqueeze(1), \n",
    "                                                 last_enc, \n",
    "                                                 out_enc)\n",
    "            out_dec[:, 0, Toks.UNK] = -np.inf # ignore unknowns\n",
    "            #out_dec[torch.arange(dec_tensor.shape[0], dtype=torch.long), 0, dec_tensor[:, i]] = -np.inf\n",
    "            chosen = torch.argmax(out_dec[:,0],dim=1)\n",
    "            dec_tensor[:, i+1] = chosen\n",
    "            last_enc = hid_dec\n",
    "    \n",
    "    return dec_tensor.data.cpu().numpy()[np.argsort(order)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(setup_data, input_seqs, test_style=ROM_STYLE):\n",
    "    input_rems_text = input_seqs\n",
    "    slen = len(input_seqs)\n",
    "    for i in range(slen):\n",
    "        input_rems_text[i].append(COCO_STYLE)\n",
    "\n",
    "    _, _, enc_tok_text, _ = tokenize_text(input_rems_text, \n",
    "                                          idx_to_word=setup_data['enc_idx_to_word'],\n",
    "                                          word_to_idx = setup_data['enc_word_to_idx'])\n",
    "    enc_padded_text = pad_text(enc_tok_text)\n",
    "\n",
    "    dlen = enc_padded_text.shape[0]\n",
    "    num_batch = int(dlen/BATCH_SIZE)\n",
    "    \n",
    "    print(num_batch)\n",
    "    if dlen % BATCH_SIZE != 0:\n",
    "        num_batch+=1\n",
    "    res = []\n",
    "    for i in range(num_batch):\n",
    "        dec_tensor = generate(setup_data['enc'], \n",
    "                              setup_data['dec'], \n",
    "                              enc_padded_text[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        res.append(dec_tensor)\n",
    "\n",
    "    all_text = []\n",
    "    res = np.concatenate(res, axis=0)\n",
    "    for row in res:\n",
    "        utok = untokenize(row, setup_data['dec_idx_to_word'], to_text=True)\n",
    "        all_text.append(utok)\n",
    "    \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./models/\"\n",
    "seq_to_seq_test_model_fname = \"seq_to_txt_state.tar\"\n",
    "BATCH_SIZE = 3\n",
    "ROM_STYLE = \"ROMANCETOKEN\"\n",
    "COCO_STYLE = \"MSCOCOTOKEN\"\n",
    "\n",
    "setup_data = setup_test()\n",
    "input_seqs = [['manNOUNNOUNNOUN', 'FRAMENETPosture', 'tennisNOUNNOUNNOUN', \n",
    "               'courtNOUNNOUNNOUN', 'FRAMENETContaining', 'racquetNOUNNOUNNOUN'], \n",
    "              ['manNOUNNOUNNOUN', 'FRAMENETPosture', 'fieldNOUNNOUNNOUN'], \n",
    "              ['bearNOUNNOUNNOUN', 'FRAMENETPlacing', 'topNOUNNOUNNOUN']]   # generate from img_to_text\n",
    "\n",
    "all_text = test(setup_data, input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a man standing on a tennis court holding a racquet',\n",
       " 'a man standing in a field',\n",
       " 'a teddy bear sitting on top of it']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a man standing on a tennis court holding a racquet',\n",
       " 'a man standing in a field of a very tall',\n",
       " 'a teddy bear sitting on top of a wooden top']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the man who was standing on the tennis court holding his racquet .',\n",
       " 'the man standing in the field .',\n",
       " 'i stuffed the bear on top of it .']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
